{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e92d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Gesture UI Recognition\n",
    "# \n",
    "# Goal: Create a model that identifies hand gestures from images\n",
    "# \n",
    "# This code closely follows the structure and libraries used in the Pokemon classification example\n",
    "\n",
    "# I have this included to suppress some tensorflow warnings and errors\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3105cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_ID = 385433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Setting Up the Dataset\n",
    "# \n",
    "# Starting with a smaller image size (128x128) for faster training, just like the Pokemon example\n",
    "\n",
    "IMG_SIZE = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "# For HAGRID dataset:\n",
    "train_dir = \"HAGRID_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset (70%)\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    image_size=IMG_SIZE, \n",
    "    validation_split=0.3,  # 30% will be split between validation and test\n",
    "    subset='training', \n",
    "    label_mode='categorical',\n",
    "    seed=STUDENT_ID, \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset (10% of total)\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    image_size=IMG_SIZE, \n",
    "    validation_split=0.3,\n",
    "    subset='validation',\n",
    "    label_mode='categorical',\n",
    "    seed=STUDENT_ID, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# In this case we're using the validation set as both validation and test\n",
    "# We'll split it further as was done in the Pokemon example\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset) // 3\n",
    "test_dataset = validation_dataset.skip(val_batches)\n",
    "validation_dataset = validation_dataset.take(val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f1c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c8f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "print(f\"Found {num_classes} classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf0c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic dataset info\n",
    "print(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88afa183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        label_index = np.argmax(labels[i])\n",
    "        plt.title(class_names[label_index])\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7970ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "model.add(layers.Rescaling(1./255))\n",
    "model.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca1d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d2635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback to prevent overfitting\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49fade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=validation_dataset, \n",
    "    epochs=100, \n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Model 2: CNN with Data Augmentation\n",
    "# \n",
    "# Adding data augmentation to improve generalization, following the Pokemon example\n",
    "data_augmentation_layers = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "model.add(data_augmentation_layers)\n",
    "model.add(layers.Rescaling(1./255))\n",
    "model.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217e3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aug = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=validation_dataset, \n",
    "    epochs=100, \n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Model 3: CNN with Data Augmentation and Dropout\n",
    "# \n",
    "# Adding dropout to further combat overfitting, just like in the Pokemon example\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "model.add(data_augmentation_layers)\n",
    "model.add(layers.Rescaling(1./255))\n",
    "model.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history_dropout = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=validation_dataset, \n",
    "    epochs=100, \n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dca5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Model 4: Grayscale Images\n",
    "# \n",
    "# Let's create a dataset with grayscale images for comparison\n",
    "# This is an addition to the Pokemon example which only used RGB\n",
    "\n",
    "\n",
    "# Load grayscale images\n",
    "train_dataset_gray = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    image_size=IMG_SIZE, \n",
    "    validation_split=0.3,\n",
    "    subset='training', \n",
    "    label_mode='categorical',\n",
    "    seed=STUDENT_ID, \n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "validation_dataset_gray = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    image_size=IMG_SIZE, \n",
    "    validation_split=0.3,\n",
    "    subset='validation',\n",
    "    label_mode='categorical',\n",
    "    seed=STUDENT_ID, \n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "# Split validation into validation and test\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset_gray) // 3\n",
    "test_dataset_gray = validation_dataset_gray.skip(val_batches)\n",
    "validation_dataset_gray = validation_dataset_gray.take(val_batches)\n",
    "\n",
    "# Optimize loading\n",
    "train_dataset_gray = train_dataset_gray.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset_gray = validation_dataset_gray.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset_gray = test_dataset_gray.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# We need to repeat the grayscale channel 3 times to match our model input shape\n",
    "def expand_grayscale(images, labels):\n",
    "    images = tf.repeat(images, 3, axis=-1)\n",
    "    return images, labels\n",
    "\n",
    "train_dataset_gray = train_dataset_gray.map(expand_grayscale)\n",
    "validation_dataset_gray = validation_dataset_gray.map(expand_grayscale)\n",
    "test_dataset_gray = test_dataset_gray.map(expand_grayscale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb9552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what a grayscale image looks like\n",
    "plt.figure(figsize=(10, 5))\n",
    "for images, labels in train_dataset_gray.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        label_index = np.argmax(labels[i])\n",
    "        plt.title(class_names[label_index])\n",
    "        plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01256514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a CNN model for grayscale\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "model.add(data_augmentation_layers)\n",
    "model.add(layers.Rescaling(1./255))\n",
    "model.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c00731",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_gray = model.fit(\n",
    "    train_dataset_gray, \n",
    "    validation_data=validation_dataset_gray, \n",
    "    epochs=100, \n",
    "    callbacks=[callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c024b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Transfer Learning\n",
    "# \n",
    "# Following the Pokemon example, we'll use transfer learning with a pre-trained model\n",
    "\n",
    "# VGG16 requires images of at least 32x32\n",
    "# Let's use 224x224 which is more standard for VGG16\n",
    "IMG_SIZE_TL = (224, 224)\n",
    "\n",
    "# Reload datasets with new image size\n",
    "train_dataset_tl = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    image_size=IMG_SIZE_TL, \n",
    "    validation_split=0.3,\n",
    "    subset='training', \n",
    "    label_mode='categorical',\n",
    "    seed=STUDENT_ID, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation_dataset_tl = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    image_size=IMG_SIZE_TL, \n",
    "    validation_split=0.3,\n",
    "    subset='validation',\n",
    "    label_mode='categorical',\n",
    "    seed=STUDENT_ID, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Split validation into validation and test\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset_tl) // 3\n",
    "test_dataset_tl = validation_dataset_tl.skip(val_batches)\n",
    "validation_dataset_tl = validation_dataset_tl.take(val_batches)\n",
    "\n",
    "# Optimize loading\n",
    "train_dataset_tl = train_dataset_tl.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset_tl = validation_dataset_tl.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset_tl = test_dataset_tl.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 pre-trained on ImageNet (same as Pokemon example)\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMG_SIZE_TL[0], IMG_SIZE_TL[1], 3),\n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a0da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define input layer\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE_TL[0], IMG_SIZE_TL[1], 3))\n",
    "\n",
    "# For data augmentation\n",
    "data_augmentation_layers_tl = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "])\n",
    "x = data_augmentation_layers_tl(inputs)\n",
    "\n",
    "# Preprocess input for VGG16\n",
    "x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "\n",
    "# Pass through base model\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Add classification head\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "outputs = layers.Dense(num_classes)(x)  # No softmax, following Pokemon example\n",
    "\n",
    "# Create model\n",
    "model = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using from_logits=True since we're not using softmax\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f2f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ac506",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c7282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_tl = model.fit(\n",
    "    train_dataset_tl, \n",
    "    validation_data=validation_dataset_tl, \n",
    "    epochs=100, \n",
    "    callbacks=[callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd615de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Transfer Learning with Dropout\n",
    "# Continuing to follow the Pokemon example, we'll add dropout to the transfer learning model\n",
    "\n",
    "\n",
    "# Define input layer\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE_TL[0], IMG_SIZE_TL[1], 3))\n",
    "\n",
    "# For data augmentation\n",
    "x = data_augmentation_layers_tl(inputs)\n",
    "\n",
    "# Preprocess input for VGG16\n",
    "x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "\n",
    "# Pass through base model\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Add classification head with dropout\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(num_classes)(x)  # No softmax\n",
    "\n",
    "# Create model\n",
    "model = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63089127",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0534ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83601700",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_tl_dropout = model.fit(\n",
    "    train_dataset_tl, \n",
    "    validation_data=validation_dataset_tl, \n",
    "    epochs=100, \n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a1dd9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m IMG_SIZE_LARGE \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m299\u001b[39m, \u001b[38;5;241m299\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Reload datasets with larger image size\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m train_dataset_large \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     11\u001b[0m     train_dir,\n\u001b[0;32m     12\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mIMG_SIZE_LARGE, \n\u001b[0;32m     14\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[0;32m     15\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     16\u001b[0m     label_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m     seed\u001b[38;5;241m=\u001b[39mSTUDENT_ID, \n\u001b[0;32m     18\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m validation_dataset_large \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     22\u001b[0m     train_dir,\n\u001b[0;32m     23\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Split validation into validation and test\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# ## Transfer Learning with Larger Images\n",
    "# \n",
    "# Following the Pokemon example, which found that 299x299 images gave the best results\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "IMG_SIZE_LARGE = (299, 299)\n",
    "\n",
    "# Reload datasets with larger image size\n",
    "train_dataset_large = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    image_size=IMG_SIZE_LARGE, \n",
    "    validation_split=0.3,\n",
    "    subset='training', \n",
    "    label_mode='categorical',\n",
    "    seed=STUDENT_ID, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation_dataset_large = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    image_size=IMG_SIZE_LARGE, \n",
    "    validation_split=0.3,\n",
    "    subset='validation',\n",
    "    label_mode='categorical',\n",
    "    seed=STUDENT_ID, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Split validation into validation and test\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset_large) // 3\n",
    "test_dataset_large = validation_dataset_large.skip(val_batches)\n",
    "validation_dataset_large = validation_dataset_large.take(val_batches)\n",
    "\n",
    "# Optimize loading\n",
    "train_dataset_large = train_dataset_large.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset_large = validation_dataset_large.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset_large = test_dataset_large.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "# Load VGG16 for larger images\n",
    "base_model_large = tf.keras.applications.VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMG_SIZE_LARGE[0], IMG_SIZE_LARGE[1], 3),\n",
    "    include_top=False\n",
    ")\n",
    "base_model_large.trainable = False\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "# Define input layer\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE_LARGE[0], IMG_SIZE_LARGE[1], 3))\n",
    "\n",
    "# For data augmentation\n",
    "data_augmentation_layers_large = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "])\n",
    "x = data_augmentation_layers_large(inputs)\n",
    "\n",
    "# Preprocess input for VGG16\n",
    "x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "\n",
    "# Pass through base model\n",
    "x = base_model_large(x, training=False)\n",
    "\n",
    "# Add classification head\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "outputs = layers.Dense(num_classes)(x)  # No softmax\n",
    "\n",
    "# Create model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=8, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "history_large = model.fit(\n",
    "    train_dataset_large, \n",
    "    validation_data=validation_dataset_large, \n",
    "    epochs=100, \n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n",
    "# ## Evaluation\n",
    "# \n",
    "# Let's evaluate our best model on the test set\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "# Create a probability model for predictions\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "# Evaluate on test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset_large)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# ## Confusion Matrix\n",
    "# Let's create a confusion matrix to understand per-class performance\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predictions\n",
    "predictions = np.array([])\n",
    "true_labels = np.array([])\n",
    "\n",
    "for x, y in test_dataset_large:\n",
    "    pred = model(x)\n",
    "    pred = tf.nn.softmax(pred)\n",
    "    pred_class = tf.argmax(pred, axis=1).numpy()\n",
    "    true_class = tf.argmax(y, axis=1).numpy()\n",
    "    \n",
    "    predictions = np.concatenate([predictions, pred_class]) if predictions.size else pred_class\n",
    "    true_labels = np.concatenate([true_labels, true_class]) if true_labels.size else true_class\n",
    "\n",
    "# Create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Add text annotations to the confusion matrix\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ## Testing on Custom Images\n",
    "# \n",
    "# Let's test our model on some custom images of gestures\n",
    "# This part is specific to the project requirements\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Replace these with paths to your own gesture images\n",
    "custom_image_paths = [\n",
    "    \"gesture1.jpg\",\n",
    "    \"gesture2.jpg\",\n",
    "    \"gesture3.jpg\",\n",
    "    \"gesture4.jpg\"\n",
    "]\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, image_path in enumerate(custom_image_paths):\n",
    "    # Load and resize image\n",
    "    try:\n",
    "        img = Image.open(image_path).resize((IMG_SIZE_LARGE[0], IMG_SIZE_LARGE[1]))\n",
    "        img_array = np.array(img)\n",
    "        img_array = np.expand_dims(img_array, 0)  # Add batch dimension\n",
    "        \n",
    "        # Make prediction\n",
    "        predictions = probability_model.predict(img_array)\n",
    "        predicted_class = np.argmax(predictions[0])\n",
    "        confidence = predictions[0][predicted_class]\n",
    "        \n",
    "        # Display image and prediction\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Predicted: {class_names[predicted_class]}\\nConfidence: {confidence:.2f}\")\n",
    "        plt.axis(\"off\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ## Summary of Results\n",
    "# \n",
    "# Let's create a summary table to compare all our models, following the assignment requirements\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "# Create a dictionary to store results\n",
    "model_results = {\n",
    "    \"Model\": [\n",
    "        \"Basic CNN\", \n",
    "        \"CNN with Data Augmentation\", \n",
    "        \"CNN with Augmentation & Dropout\",\n",
    "        \"CNN with Grayscale Images\",\n",
    "        \"Transfer Learning (VGG16, 224x224)\",\n",
    "        \"Transfer Learning with Dropout\",\n",
    "        \"Transfer Learning (VGG16, 299x299)\"\n",
    "    ],\n",
    "    \"Training Accuracy\": [\n",
    "        max(history.history['accuracy']),\n",
    "        max(history_aug.history['accuracy']),\n",
    "        max(history_dropout.history['accuracy']),\n",
    "        max(history_gray.history['accuracy']),\n",
    "        max(history_tl.history['accuracy']),\n",
    "        max(history_tl_dropout.history['accuracy']),\n",
    "        max(history_large.history['accuracy'])\n",
    "    ],\n",
    "    \"Validation Accuracy\": [\n",
    "        max(history.history['val_accuracy']),\n",
    "        max(history_aug.history['val_accuracy']),\n",
    "        max(history_dropout.history['val_accuracy']),\n",
    "        max(history_gray.history['val_accuracy']),\n",
    "        max(history_tl.history['val_accuracy']),\n",
    "        max(history_tl_dropout.history['val_accuracy']),\n",
    "        max(history_large.history['val_accuracy'])\n",
    "    ],\n",
    "    \"Test Accuracy\": [\n",
    "        \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", test_accuracy\n",
    "    ],\n",
    "    \"Training Time (epochs)\": [\n",
    "        len(history.history['accuracy']),\n",
    "        len(history_aug.history['accuracy']),\n",
    "        len(history_dropout.history['accuracy']),\n",
    "        len(history_gray.history['accuracy']),\n",
    "        len(history_tl.history['accuracy']),\n",
    "        len(history_tl_dropout.history['accuracy']),\n",
    "        len(history_large.history['accuracy'])\n",
    "    ],\n",
    "    \"Parameters\": [\n",
    "        model.count_params(),\n",
    "        model.count_params(),\n",
    "        model.count_params(),\n",
    "        model.count_params(),\n",
    "        model.count_params(),\n",
    "        model.count_params(),\n",
    "        model.count_params()\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame and display\n",
    "results_df = pd.DataFrame(model_results)\n",
    "print(results_df)\n",
    "\n",
    "# Save results to CSV for the paper\n",
    "results_df.to_csv(\"model_comparison_results.csv\", index=False)\n",
    "\n",
    "# ## Save the Best Model\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "# Save the model for future use\n",
    "model.save(\"best_gesture_recognition_model\")\n",
    "\n",
    "print(\"Training and evaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
